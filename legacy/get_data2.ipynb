{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba18eaf6-e231-4086-aa2f-a62a2d331d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Requirement already satisfied: pandas in /opt/mamba/lib/python3.10/site-packages (2.2.0)\n",
      "Collecting pyreadr\n",
      "  Downloading pyreadr-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/mamba/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pyreadr-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.9/440.9 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyreadr\n",
      "Successfully installed pyreadr-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet\n",
    "!pip install pandas pyreadr\n",
    "import chardet\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import re\n",
    "import requests\n",
    "import s3fs\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f58bd8a-c51d-4b09-8d85-c5b0e5c4244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 67 files to download.\n"
     ]
    }
   ],
   "source": [
    "# Identification des fichiers csv\n",
    "def extract_strings_from_webpage(url):\n",
    "    response = requests.get(url) \n",
    "    if response.status_code == 200:\n",
    "        strings = re.findall(r'\"([^\"]*)\"', response.text)\n",
    "        return strings\n",
    "    else:\n",
    "        print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "webpage_url = \"https://unehistoireduconflitpolitique.fr/telecharger.html\"\n",
    "extracted_strings = extract_strings_from_webpage(webpage_url)\n",
    "download_links = [item for item in extracted_strings if item.endswith(\"csv.zip\") or item.endswith(\"csp.zip\")]\n",
    "print(f\"Identified {len(download_links)} files to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03efe9a8-a9a8-4a43-b416-bf4bb180f28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 67/67 [00:36<00:00,  1.83file/s]\n"
     ]
    }
   ],
   "source": [
    "# Téléchargement des fichiers\n",
    "os.makedirs('data_zip', exist_ok=True)\n",
    "\n",
    "progress_bar = tqdm(total=len(download_links), desc=\"Downloading\", unit=\"file\")\n",
    "\n",
    "for link in download_links:\n",
    "    try:\n",
    "        file_name = os.path.join('data_zip', os.path.basename(link))\n",
    "        response = requests.get(link)\n",
    "        with open(file_name, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        progress_bar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {link}: {e}\")\n",
    "        \n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b07636-d58e-4919-a226-aa50d18d9008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 57/57 [00:10<00:00,  5.69file/s]\n"
     ]
    }
   ],
   "source": [
    "# Extraction des résultats électoraux\n",
    "for prefix in ['pres', 'leg', 'ref']:\n",
    "    prefix_dir = os.path.join('data_csv', 'Elections_' + prefix)\n",
    "    os.makedirs(prefix_dir, exist_ok=True)\n",
    "\n",
    "zip_files = [file for file in os.listdir('data_zip') if file.endswith('.zip')]\n",
    "total_zip_files = sum(file.startswith(prefix) for prefix in ['pres', 'leg', 'ref'] for file in zip_files)\n",
    "progress_bar = tqdm(total=total_zip_files, desc=\"Extracting\", unit=\"file\")\n",
    "\n",
    "for prefix in ['pres', 'leg', 'ref']:\n",
    "    for file in zip_files:\n",
    "        if file.startswith(prefix) and file.endswith('.zip'):\n",
    "            try:\n",
    "                zip_file_path = os.path.join('data_zip', file)\n",
    "                prefix_dir = os.path.join('data_csv', 'Elections_' + prefix)\n",
    "                with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                    for member in zip_ref.infolist():\n",
    "                        if member.filename.lower().endswith('.csv'):\n",
    "                            target_path = os.path.join(prefix_dir, os.path.basename(member.filename))\n",
    "                            with zip_ref.open(member) as source, open(target_path, 'wb') as dest:\n",
    "                                shutil.copyfileobj(source, dest)\n",
    "                os.remove(zip_file_path)\n",
    "                progress_bar.update(1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {file}: {e}\")\n",
    "            \n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6485778-11b9-4780-9a7b-b47562db7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deletion of extra files completed.\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage des résultats électoraux\n",
    "for root, dirs, files in os.walk('data_csv'):\n",
    "    for file_name in files:\n",
    "        if file_name.startswith(\"._\"):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting file {file_path}: {e}\")\n",
    "print(\"Deletion of extra files completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55488d2-9d45-49a1-8603-0ffd67b664a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 10/10 [00:34<00:00,  3.40s/file]\n"
     ]
    }
   ],
   "source": [
    "# Extraction des contrôles\n",
    "zip_files = [f for f in os.listdir('data_zip') if f.endswith('.zip')]\n",
    "total_zip_files = sum(not any(file.startswith(prefix) for prefix in ['pres', 'leg', 'ref']) for file in zip_files)\n",
    "progress_bar = tqdm(total=total_zip_files, desc=\"Extracting\", unit=\"file\")\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    if zip_file.startswith(('pres', 'leg', 'ref')):\n",
    "        continue\n",
    "    zip_path = os.path.join('data_zip', zip_file)\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            file_list = [file for file in zip_ref.namelist() if not file.startswith('__MACOSX')]\n",
    "            zip_ref.extractall('data_csv', members=file_list)\n",
    "            os.remove(zip_path)            \n",
    "            progress_bar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {zip_file}: {e}\")\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029b864d-a390-4f9f-8c3b-70b8d9fdeb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage des contrôles\n",
    "folders = [f for f in os.listdir('data_csv') if os.path.isdir(os.path.join('data_csv', f))]\n",
    "for folder in folders:\n",
    "    if folder.endswith('_csv'):\n",
    "        old_path = os.path.join('data_csv', folder)\n",
    "        new_folder_name = folder[:-4]\n",
    "        new_path = os.path.join('data_csv', new_folder_name)\n",
    "        os.rename(old_path, new_path)\n",
    "\n",
    "shutil.move('data_csv/alphabetisationcommunes.csv', 'data_csv/Diplomes/')\n",
    "\n",
    "print(\"Folder cleaning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42722a4a-81b5-4626-830d-eddb31cb3ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data removed.\n"
     ]
    }
   ],
   "source": [
    "# Suppression du répertoire de téléchargement\n",
    "shutil.rmtree('data_zip')\n",
    "print('Downloaded data removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e1c16a-e0fb-4e08-8731-4113a628b83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of extracted data: 6580.59 MB.\n"
     ]
    }
   ],
   "source": [
    "# Caclul de la taille des données converties\n",
    "try:\n",
    "    total_size = 0\n",
    "    for foldername, subfolders, filenames in os.walk('data_csv'):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            total_size += os.path.getsize(filepath)\n",
    "    total_size_mb = total_size / (1024 * 1024)\n",
    "    print(f'Total size of extracted data: {total_size_mb:.2f} MB.')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb5749b-347d-4bcf-9374-f8fe2a022812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage du datalab\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73dacdc0-5393-4a43-b967-3d8d7b55f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 110/110 [02:48<00:00,  1.53s/file]\n"
     ]
    }
   ],
   "source": [
    "# Transmission des données vers le datalab\n",
    "source_directory = 'data_csv'\n",
    "bucket_name = 'maeldieudonne'\n",
    "destination_directory = bucket_name + '/diffusion/csv'\n",
    "\n",
    "total_files = sum([len(files) for _, _, files in os.walk(source_directory)])\n",
    "progress_bar = tqdm(total=total_files, desc=\"Uploading\", unit=\"file\")\n",
    "\n",
    "for root, dirs, files in os.walk(source_directory):\n",
    "    for file in files:\n",
    "        source_path = os.path.join(root, file)\n",
    "        destination_path = os.path.join(destination_directory, os.path.relpath(source_path, source_directory))\n",
    "        fs.put(source_path, destination_path, content_type='text/csv', encoding='utf-8')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
