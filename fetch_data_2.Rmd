```{r include=FALSE}
if (!"reticulate" %in% installed.packages()) install.packages("reticulate")
if (!is.loaded("reticulate")) library(reticulate)
if (py_available() == FALSE) install_miniconda()
if (!("r-reticulate" %in% conda_list()$name)) conda_create("r-reticulate")
use_condaenv("r-reticulate")
```

```{r}
package_list <- c("chardet", "pandas", "pyarrow", "requests", "s3fs", "tqdm")
py_install(package_list, pip = TRUE)
rm(package_list)
```

```{python}
import chardet
import os
import pandas as pd
import pyarrow.feather as feather
import re
import requests
import s3fs
import shutil
from tqdm import tqdm
import zipfile
```

```{python}
# Identification des fichiers
def extract_strings_from_webpage(url):
    response = requests.get(url) 
    if response.status_code == 200:
        strings = re.findall(r'"([^"]*)"', response.text)
        return strings
    else:
        print(f"Failed to fetch the webpage. Status code: {response.status_code}")
        return []

webpage_url = "https://unehistoireduconflitpolitique.fr/telecharger.html"
extracted_strings = extract_strings_from_webpage(webpage_url)
download_links = [item for item in extracted_strings if item.endswith("csv.zip") or item.endswith("csp.zip")]
print(f"Identified {len(download_links)} files to download.")
```

```{python}
# Téléchargement des fichiers
os.makedirs('data_zip', exist_ok=True)

progress_bar = tqdm(total=len(download_links), desc="Downloading", unit="file")

for link in download_links:
    try:
        file_name = os.path.join('data_zip', os.path.basename(link))
        response = requests.get(link)
        with open(file_name, 'wb') as file:
            file.write(response.content)
        progress_bar.update(1)
    except Exception as e:
        print(f"Error downloading {link}: {e}")
        
progress_bar.close()
```

```{python}
# Caclul de la taille des données téléchargées
try:
    total_size = 0
    for foldername, subfolders, filenames in os.walk('data_zip'):
        for filename in filenames:
            filepath = os.path.join(foldername, filename)
            total_size += os.path.getsize(filepath)
    total_size_mb = total_size / (1024 * 1024)
    print(f'Total size of downloaded files: {total_size_mb:.2f} MB.')
except Exception as e:
    print(f'An error occurred: {e}')
```

```{python}
# Extraction des résultats électoraux
for prefix in ['pres', 'leg', 'ref']:
    prefix_dir = os.path.join('data_csv', 'Elections_' + prefix)
    os.makedirs(prefix_dir, exist_ok=True)

zip_files = [file for file in os.listdir('data_zip') if file.endswith('.zip')]
total_zip_files = sum(file.startswith(prefix) for prefix in ['pres', 'leg', 'ref'] for file in zip_files)
progress_bar = tqdm(total=total_zip_files, desc="Extracting", unit="file")

for prefix in ['pres', 'leg', 'ref']:
    for file in zip_files:
        if file.startswith(prefix) and file.endswith('.zip'):
            try:
                zip_file_path = os.path.join('data_zip', file)
                prefix_dir = os.path.join('data_csv', 'Elections_' + prefix)
                with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
                    for member in zip_ref.infolist():
                        if member.filename.lower().endswith('.csv'):
                            target_path = os.path.join(prefix_dir, os.path.basename(member.filename))
                            with zip_ref.open(member) as source, open(target_path, 'wb') as dest:
                                shutil.copyfileobj(source, dest)
                progress_bar.update(1)
            except Exception as e:
                print(f"Error converting {file}: {e}")
            
progress_bar.close()
```

```{python}
# Nettoyage des résultats électoraux
for root, dirs, files in os.walk('data_csv'):
    for file_name in files:
        if file_name.startswith("._"):
            file_path = os.path.join(root, file_name)
            try:
                os.remove(file_path)
            except Exception as e:
                print(f"Error deleting file {file_path}: {e}")
print("Folder cleaning completed.")
```

```{python}
# Extraction des contrôles
zip_files = [f for f in os.listdir('data_zip') if f.endswith('.zip')]
total_zip_files = sum(not any(file.startswith(prefix) for prefix in ['pres', 'leg', 'ref']) for file in zip_files)
progress_bar = tqdm(total=total_zip_files, desc="Extracting", unit="file")

for zip_file in zip_files:
    if zip_file.startswith(('pres', 'leg', 'ref')):
        continue
    zip_path = os.path.join('data_zip', zip_file)
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            file_list = [file for file in zip_ref.namelist() if not file.startswith('__MACOSX')]
            zip_ref.extractall('data_csv', members=file_list)
        progress_bar.update(1)
    except Exception as e:
        print(f"Error extracting {zip_file}: {e}")

progress_bar.close()
```

```{python}
# Nettoyage des contrôles
folders = [f for f in os.listdir('data_csv') if os.path.isdir(os.path.join('data_csv', f))]
for folder in folders:
    if folder.endswith('_csv'):
        old_path = os.path.join('data_csv', folder)
        new_folder_name = folder[:-4]
        new_path = os.path.join('data_csv', new_folder_name)
        os.rename(old_path, new_path)

shutil.move('data_csv/alphabetisationcommunes.csv', 'data_csv/Diplomes/')

print("Folder cleaning complete.")
```

```{python}
# Caclul de la taille des données extraites
try:
    total_size = 0
    for foldername, subfolders, filenames in os.walk('data_csv'):
        for filename in filenames:
            filepath = os.path.join(foldername, filename)
            total_size += os.path.getsize(filepath)
    total_size_mb = total_size / (1024 * 1024)
    print(f'Total size of extracted data: {total_size_mb:.2f} MB.')
except Exception as e:
    print(f'An error occurred: {e}')
```

```{python}
# Conversion au format Feather (avec détection automatique de l'encodage, sans compression)
total_csv_files = 0
for root, dirs, files in os.walk('data_csv'):
    csv_files = [file for file in files if file.endswith(".csv")]
    total_csv_files += len(csv_files)
progress_bar = tqdm(total=total_csv_files, desc="Converting", unit="file")

for root, dirs, files in os.walk('data_csv'):
    for file in files:
        if file.endswith(".csv"):
            try:
                input_csv_path = os.path.join(root, file)
                relative_path = os.path.relpath(input_csv_path, 'data_csv')
                output_feather_path = os.path.join('data_feather', os.path.splitext(relative_path)[0] + ".feather")
                os.makedirs(os.path.dirname(output_feather_path), exist_ok=True)
                # Détection du format d'encodage
                with open(input_csv_path, 'rb') as f:
                    result = chardet.detect(f.read())
                encoding = result['encoding']
                # Lecture du fichier CSV
                data = pd.read_csv(input_csv_path, low_memory=False, encoding=encoding)
                # Écriture du fichier Feather
                feather.write_feather(data, output_feather_path)
                # Affichage de la progression
                progress_bar.update(1)
                # Suppression du fichier CSV initial
                os.remove(input_csv_path)
            except Exception as e:
                print(f"Error converting {input_csv_path}: {e}")

progress_bar.close()
```

```{python}
import pyarrow as pa
import pyarrow.parquet as pq

# Conversion au format Parquet (avec détection automatique de l'encodage, sans compression)
total_csv_files = 0
for root, dirs, files in os.walk('data_csv'):
    csv_files = [file for file in files if file.endswith(".csv")]
    total_csv_files += len(csv_files)
progress_bar = tqdm(total=total_csv_files, desc="Converting", unit="file")

for root, dirs, files in os.walk('data_csv'):
    for file in files:
        if file.endswith(".csv"):
            try:
                input_csv_path = os.path.join(root, file)
                relative_path = os.path.relpath(input_csv_path, 'data_csv')
                output_parquet_path = os.path.join('data_parquet', os.path.splitext(relative_path)[0] + ".parquet")
                os.makedirs(os.path.dirname(output_parquet_path), exist_ok=True)
                # Détection du format d'encodage
                with open(input_csv_path, 'rb') as f:
                    result = chardet.detect(f.read())
                encoding = result['encoding']
                # Lecture du fichier CSV
                data = pd.read_csv(input_csv_path, low_memory=False, encoding=encoding)
                # Écriture du fichier Parquet
                table = pa.Table.from_pandas(data)
                pq.write_table(table, output_parquet_path)
                # Affichage de la progression
                progress_bar.update(1)
            except Exception as e:
                print(f"Error converting {input_csv_path}: {e}")

progress_bar.close()
```
