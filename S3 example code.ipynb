{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02dfd3c-4a46-47be-98c3-d86260c1b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import s3fs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c79417-4210-46c7-8542-94fd51133f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c95c6e-488b-4003-b9bf-45ccab91c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test écriture\n",
    "# D'après l'exemple proposé dans la doc : le dataframe est écrit en csv dans S3.\n",
    "BUCKET_OUT = \"maeldieudonne\"\n",
    "FILE_KEY_OUT_S3 = \"diffusion/ref2005comm.csv\"\n",
    "FILE_PATH_OUT_S3 = BUCKET_OUT + \"/\" + FILE_KEY_OUT_S3\n",
    "\n",
    "df_bpe = pd.read_csv(\"ref2005comm.csv\", low_memory=False)\n",
    "    \n",
    "with fs.open(FILE_PATH_OUT_S3, 'w') as file_out:\n",
    "    df_bpe.to_csv(file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6572c60-7c3c-4f96-a91c-f85622cf493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test lecture \n",
    "BUCKET = \"maeldieudonne\"\n",
    "FILE_KEY_S3 = \"diffusion/ref2005comm.csv\"\n",
    "FILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n",
    "\n",
    "with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "    df_ref2005 = pd.read_csv(file_in, low_memory=False, sep=\",\")\n",
    "\n",
    "df_ref2005.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff45a5a-8cf0-48db-857f-e9ccc49f4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test écriture 2 - pour uploader l'ensemble du répertoire sans conversion en df\n",
    "local_directory = 'data_csv'\n",
    "bucket_name = 'maeldieudonne'\n",
    "s3_destination_directory = bucket_name + '/diffusion/'\n",
    "fs.put(local_directory, s3_destination_directory, recursive=True, content_type='text/csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12543673-d339-457b-bd74-610458ae0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test lecture 2\n",
    "BUCKET = \"maeldieudonne\"\n",
    "FILE_KEY_S3 = \"diffusion/data_csv/elections/ref2005comm.csv\"\n",
    "FILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n",
    "\n",
    "with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "    df_ref2005 = pd.read_csv(file_in, low_memory=False, sep=\",\")\n",
    "\n",
    "df_ref2005"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
