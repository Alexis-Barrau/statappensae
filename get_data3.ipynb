{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba18eaf6-e231-4086-aa2f-a62a2d331d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Requirement already satisfied: pandas in /opt/mamba/lib/python3.10/site-packages (2.2.0)\n",
      "Collecting pyreadr\n",
      "  Downloading pyreadr-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/mamba/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/mamba/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pyreadr-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.9/440.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyreadr\n",
      "Successfully installed pyreadr-0.5.0\n",
      "Requirement already satisfied: pyarrow in /opt/mamba/lib/python3.10/site-packages (14.0.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/mamba/lib/python3.10/site-packages (from pyarrow) (1.26.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet\n",
    "!pip install pandas pyreadr\n",
    "!pip install pyarrow\n",
    "import chardet\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import pyreadr\n",
    "import re\n",
    "import requests\n",
    "import s3fs\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f58bd8a-c51d-4b09-8d85-c5b0e5c4244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 67 files to download.\n"
     ]
    }
   ],
   "source": [
    "# Identification des fichiers csv\n",
    "def extract_strings_from_webpage(url):\n",
    "    response = requests.get(url) \n",
    "    if response.status_code == 200:\n",
    "        strings = re.findall(r'\"([^\"]*)\"', response.text)\n",
    "        return strings\n",
    "    else:\n",
    "        print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "webpage_url = \"https://unehistoireduconflitpolitique.fr/telecharger.html\"\n",
    "extracted_strings = extract_strings_from_webpage(webpage_url)\n",
    "download_links = [item for item in extracted_strings if item.endswith(\"csv.zip\") or item.endswith(\"csp.zip\")]\n",
    "print(f\"Identified {len(download_links)} files to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03efe9a8-a9a8-4a43-b416-bf4bb180f28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 67/67 [00:38<00:00,  1.74file/s]\n"
     ]
    }
   ],
   "source": [
    "# Téléchargement des fichiers\n",
    "os.makedirs('data_zip', exist_ok=True)\n",
    "\n",
    "progress_bar = tqdm(total=len(download_links), desc=\"Downloading\", unit=\"file\")\n",
    "\n",
    "for link in download_links:\n",
    "    try:\n",
    "        file_name = os.path.join('data_zip', os.path.basename(link))\n",
    "        response = requests.get(link)\n",
    "        with open(file_name, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        progress_bar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {link}: {e}\")\n",
    "        \n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3298c136-7bfb-4936-ac33-bdf85328ec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of downloaded data: 2063.75 MB.\n"
     ]
    }
   ],
   "source": [
    "# Caclul de la taille des données téléchargées\n",
    "try:\n",
    "    total_size = 0\n",
    "    for foldername, subfolders, filenames in os.walk('data_zip'):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            total_size += os.path.getsize(filepath)\n",
    "    total_size_mb = total_size / (1024 * 1024)\n",
    "    print(f'Total size of downloaded files: {total_size_mb:.2f} MB.')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b07636-d58e-4919-a226-aa50d18d9008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 57/57 [00:10<00:00,  5.31file/s]\n"
     ]
    }
   ],
   "source": [
    "# Extraction des résultats électoraux\n",
    "for prefix in ['pres', 'leg', 'ref']:\n",
    "    prefix_dir = os.path.join('data_csv', 'Elections_' + prefix)\n",
    "    os.makedirs(prefix_dir, exist_ok=True)\n",
    "\n",
    "zip_files = [file for file in os.listdir('data_zip') if file.endswith('.zip')]\n",
    "total_zip_files = sum(file.startswith(prefix) for prefix in ['pres', 'leg', 'ref'] for file in zip_files)\n",
    "progress_bar = tqdm(total=total_zip_files, desc=\"Extracting\", unit=\"file\")\n",
    "\n",
    "for prefix in ['pres', 'leg', 'ref']:\n",
    "    for file in zip_files:\n",
    "        if file.startswith(prefix) and file.endswith('.zip'):\n",
    "            try:\n",
    "                zip_file_path = os.path.join('data_zip', file)\n",
    "                prefix_dir = os.path.join('data_csv', 'Elections_' + prefix)\n",
    "                with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                    for member in zip_ref.infolist():\n",
    "                        if member.filename.lower().endswith('.csv'):\n",
    "                            target_path = os.path.join(prefix_dir, os.path.basename(member.filename))\n",
    "                            with zip_ref.open(member) as source, open(target_path, 'wb') as dest:\n",
    "                                shutil.copyfileobj(source, dest)\n",
    "                os.remove(zip_file_path)\n",
    "                progress_bar.update(1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {file}: {e}\")\n",
    "            \n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6485778-11b9-4780-9a7b-b47562db7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deletion of extra files completed.\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage des résultats électoraux\n",
    "for root, dirs, files in os.walk('data_csv'):\n",
    "    for file_name in files:\n",
    "        if file_name.startswith(\"._\"):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting file {file_path}: {e}\")\n",
    "print(\"Deletion of extra files completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55488d2-9d45-49a1-8603-0ffd67b664a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 10/10 [00:30<00:00,  3.00s/file]\n"
     ]
    }
   ],
   "source": [
    "# Extraction des contrôles\n",
    "zip_files = [f for f in os.listdir('data_zip') if f.endswith('.zip')]\n",
    "total_zip_files = sum(not any(file.startswith(prefix) for prefix in ['pres', 'leg', 'ref']) for file in zip_files)\n",
    "progress_bar = tqdm(total=total_zip_files, desc=\"Extracting\", unit=\"file\")\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    if zip_file.startswith(('pres', 'leg', 'ref')):\n",
    "        continue\n",
    "    zip_path = os.path.join('data_zip', zip_file)\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            file_list = [file for file in zip_ref.namelist() if not file.startswith('__MACOSX')]\n",
    "            zip_ref.extractall('data_csv', members=file_list)\n",
    "            os.remove(zip_path)            \n",
    "            progress_bar.update(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {zip_file}: {e}\")\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029b864d-a390-4f9f-8c3b-70b8d9fdeb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage des contrôles\n",
    "folders = [f for f in os.listdir('data_csv') if os.path.isdir(os.path.join('data_csv', f))]\n",
    "for folder in folders:\n",
    "    if folder.endswith('_csv'):\n",
    "        old_path = os.path.join('data_csv', folder)\n",
    "        new_folder_name = folder[:-4]\n",
    "        new_path = os.path.join('data_csv', new_folder_name)\n",
    "        os.rename(old_path, new_path)\n",
    "\n",
    "shutil.move('data_csv/alphabetisationcommunes.csv', 'data_csv/Diplomes/')\n",
    "\n",
    "print(\"Folder cleaning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f42a3af-1296-4f58-879e-444f031a08ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of extracted data: 6580.59 MB.\n"
     ]
    }
   ],
   "source": [
    "# Caclul de la taille des données extraites\n",
    "try:\n",
    "    total_size = 0\n",
    "    for foldername, subfolders, filenames in os.walk('data_csv'):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            total_size += os.path.getsize(filepath)\n",
    "    total_size_mb = total_size / (1024 * 1024)\n",
    "    print(f'Total size of extracted data: {total_size_mb:.2f} MB.')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42722a4a-81b5-4626-830d-eddb31cb3ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data removed.\n"
     ]
    }
   ],
   "source": [
    "# Suppression du répertoire de téléchargement\n",
    "shutil.rmtree('data_zip')\n",
    "print('Downloaded data removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4b7205-c894-43c1-bc67-506e4c9067b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 110/110 [2:11:57<00:00, 71.97s/file]   \n"
     ]
    }
   ],
   "source": [
    "# Conversion au format Feather (avec détection automatique de l'encodage, sans compression)\n",
    "total_csv_files = 0\n",
    "for root, dirs, files in os.walk('data_csv'):\n",
    "    csv_files = [file for file in files if file.endswith(\".csv\")]\n",
    "    total_csv_files += len(csv_files)\n",
    "progress_bar = tqdm(total=total_csv_files, desc=\"Converting\", unit=\"file\")\n",
    "\n",
    "for root, dirs, files in os.walk('data_csv'):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            try:\n",
    "                input_csv_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(input_csv_path, 'data_csv')\n",
    "                output_feather_path = os.path.join('data_feather', os.path.splitext(relative_path)[0] + \".feather\")\n",
    "                os.makedirs(os.path.dirname(output_feather_path), exist_ok=True)\n",
    "                # Détection du format d'encodage\n",
    "                with open(input_csv_path, 'rb') as f:\n",
    "                    result = chardet.detect(f.read())\n",
    "                encoding = result['encoding']\n",
    "                # Lecture du fichier CSV\n",
    "                data = pd.read_csv(input_csv_path, low_memory=False, encoding=encoding)\n",
    "                # Écriture du fichier Feather\n",
    "                feather.write_feather(data, output_feather_path)\n",
    "                # Affichage de la progression\n",
    "                progress_bar.update(1)\n",
    "                # Suppression du fichier CSV initial\n",
    "                os.remove(input_csv_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {input_csv_path}: {e}\")\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e1c16a-e0fb-4e08-8731-4113a628b83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of converted data: 4716.75 MB.\n"
     ]
    }
   ],
   "source": [
    "# Caclul de la taille des données converties\n",
    "try:\n",
    "    total_size = 0\n",
    "    for foldername, subfolders, filenames in os.walk('data_feather'):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            total_size += os.path.getsize(filepath)\n",
    "    total_size_mb = total_size / (1024 * 1024)\n",
    "    print(f'Total size of converted data: {total_size_mb:.2f} MB.')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df973806-fe31-4dd5-aeac-7e7c69b2ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data removed.\n"
     ]
    }
   ],
   "source": [
    "# Suppression du répertoire d'extraction\n",
    "shutil.rmtree('data_csv')\n",
    "print('Extracted data removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb76a6c-ea4b-4f20-baba-b8a3f0701a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage du datalab\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b56b2d7b-4e31-4374-a89b-94e2e1699051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 110/110 [02:11<00:00,  1.19s/file]\n"
     ]
    }
   ],
   "source": [
    "# Transmission des données vers le datalab\n",
    "source_directory = 'data_feather'\n",
    "bucket_name = 'maeldieudonne'\n",
    "destination_directory = bucket_name + '/diffusion/'\n",
    "\n",
    "total_files = sum([len(files) for _, _, files in os.walk(source_directory)])\n",
    "progress_bar = tqdm(total=total_files, desc=\"Uploading\", unit=\"file\")\n",
    "\n",
    "for root, dirs, files in os.walk(source_directory):\n",
    "    for file in files:\n",
    "        source_path = os.path.join(root, file)\n",
    "        destination_path = os.path.join(destination_directory, os.path.relpath(source_path, source_directory))\n",
    "        fs.put(source_path, destination_path, content_type='text/csv', encoding='utf-8')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988031d6-1c79-4d39-b80c-0e0f1f8f4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression du répertoire de conversion\n",
    "shutil.rmtree('data_feather')\n",
    "print('Converted data removed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
